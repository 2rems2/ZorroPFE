# -*- coding: utf-8 -*-
"""PFETest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-yRXgJMsyuI2x_MCytoxSpUsSso8NZG-
"""

!pip install --upgrade pip
!pip install -U torch torchvision torchaudio
!pip install transformers accelerate --quiet
!pip install transformers --quiet

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch
import json
from huggingface_hub import login
from transformers import AutoTokenizer, AutoModelForCausalLM

login(token="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")

model_id = "mistralai/Mistral-7B-Instruct-v0.1"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, device_map="auto", torch_dtype=torch.float16)

# === ğŸš€ Colab : importer le fichier depuis ton ordinateur ===
from google.colab import files
import json

# TÃ©lÃ©charger le fichier JSON depuis ton poste
uploaded = files.upload()  # Choisis "ressources_simple.json" dans la fenÃªtre

# Lecture du fichier
with open("ressources_simple.json", "r", encoding="utf-8") as f:
    ressources = json.load(f)

# Fonction pour rÃ©cupÃ©rer les ressources selon le type de harcÃ¨lement
def get_links(abuse_type):
    return ressources.get(abuse_type.lower(), ressources["default"])


# === Version pour usage local (commentÃ©e) ===
"""
import json

with open("ressources_simple.json", "r", encoding="utf-8") as f:
    ressources = json.load(f)

def get_links(abuse_type):
    return ressources.get(abuse_type.lower(), ressources["default"])
"""

def generate_response_fr(user_message, abuse_type="default", is_abuse=0):
    # Construction du prompt selon le cas
    if is_abuse == 1:
        prompt = f"""[SystÃ¨me] Tu es un assistant bienveillant qui rÃ©dige des messages de soutien.
Tu dois toujours rÃ©pondre uniquement en franÃ§ais, en utilisant le tutoiement.
Ne dis jamais que tu peux Ã©couter ou que tu es disponible pour discuter.
Donne uniquement un message unique de soutien et un conseil adaptÃ©.

[Utilisateur] Une personne te dit : "{user_message}"
C'est un cas de harcÃ¨lement de type {abuse_type}.
RÃ©dige un message empathique, rassurant, sans jugement.
Termine en proposant une action concrÃ¨te (parler Ã  un adulte de confiance, contacter une structure...).

[Assistant]"""
    else:
        prompt = f"""[SystÃ¨me] Tu es un assistant bienveillant qui rÃ©dige des messages rÃ©confortants.
Tu dois toujours rÃ©pondre uniquement en franÃ§ais, en utilisant le tutoiement.
Ne dis jamais que tu peux Ã©couter ou que tu es disponible pour discuter.
Donne uniquement un message unique de soutien adaptÃ© Ã  lâ€™Ã©tat Ã©motionnel.

[Utilisateur] Une personne dit : "{user_message}"
MÃªme si ce nâ€™est pas un cas de harcÃ¨lement, rÃ©dige un message simple, chaleureux et rassurant.

[Assistant]"""

    # Construction des entrÃ©es pour le modÃ¨le
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    # GÃ©nÃ©ration de la rÃ©ponse
    output = model.generate(
        **inputs,
        max_new_tokens=300,
        temperature=0.7,
        top_k=50,
        top_p=0.9,
        do_sample=True,
        repetition_penalty=1.2,
        pad_token_id=tokenizer.eos_token_id
    )

    response = tokenizer.decode(output[0], skip_special_tokens=True)

    # Ajout des ressources si harcÃ¨lement
    if is_abuse == 1:
        links = get_links(abuse_type)
        response += "\n\nğŸ“Œ Ressources utiles :\n" + "\n".join(links)

    return response

# Wake-up pass (juste aprÃ¨s chargement du modÃ¨le)
tokenizer("Test", return_tensors="pt").to(model.device)
model.generate(**tokenizer("Bonjour", return_tensors="pt").to(model.device), max_new_tokens=5)

# GÃ©nÃ©ration automatique de 2 exemples par type
test_inputs = [
    # Racisme
    ("racisme", "On m'a dit de retourner dans mon pays."),
    ("racisme", "Un camarade m'appelle sans arrÃªt par des surnoms racistes."),
    # Homophobie
    ("homophobie", "Ils ont dÃ©couvert que jâ€™Ã©tais gay et mâ€™ont dit que je devrais avoir honte."),
    ("homophobie", "On mâ€™a dit que jâ€™Ã©tais une honte pour ma famille Ã  cause de mon orientation."),
    # Sexisme
    ("sexisme", "Ils mâ€™ont dit que les filles ne sont pas faites pour coder."),
    ("sexisme", "Un garÃ§on a dit que je devrais rester Ã  la maison au lieu dâ€™Ãªtre ici."),
    # Grossophobie / Physique
    ("grossophobie", "Ils se moquent de mon poids tous les jours Ã  la cantine."),
    ("physique", "Quelquâ€™un a dit que jâ€™Ã©tais trop moche pour sortir avec quelquâ€™un."),
    # Religion
    ("religion", "On mâ€™a traitÃ© de terroriste parce que je suis musulman."),
    ("religion", "On sâ€™est moquÃ© de moi parce que je portais une croix."),
    # Handicap
    ("handicap", "Ils ont rigolÃ© parce que je marche diffÃ©remment."),
    ("handicap", "Quelquâ€™un mâ€™a dit que je ne devrais pas Ãªtre dans une classe normale."),
    # Identitaire
    ("identitaire", "On mâ€™a dit que je ne devrais pas parler ma langue maternelle ici."),
    ("identitaire", "Ils se moquent de mes origines devant tout le monde."),
    # Injure
    ("injure", "Un Ã©lÃ¨ve mâ€™a insultÃ© de tous les noms dans le couloir."),
    ("injure", "On mâ€™a dit que jâ€™Ã©tais un bon Ã  rien, inutile et dÃ©bile.")
]

# Boucle de gÃ©nÃ©ration et affichage
for abuse_type, user_message in test_inputs:
    is_abuse = 1
    response = generate_response_fr(user_message, abuse_type, is_abuse)

    # Affichage
    print(f"\n---\nğŸ§· Type : {abuse_type.upper()}\nğŸ’¬ Message : {user_message}\nğŸ—¨ï¸ RÃ©ponse gÃ©nÃ©rÃ©e :\n{response}\n")

    # Stockage pour usage ultÃ©rieur
    examples_buffer.append((user_message, response.strip(), abuse_type))

"""#Partie Evaluation"""

for message, response, abuse_type in examples_buffer:
    # Trouver le dÃ©but de la rÃ©ponse assistant
    start = response.find("[Assistant]")
    if start != -1:
        assistant_text = response[start + len("[Assistant]"):].strip()
    else:
        assistant_text = response.strip()

    # Couper au premier double saut de ligne (sÃ©paration paragraphe)
    split_paragraphs = assistant_text.split("\n\n")
    main_response = split_paragraphs[0].strip()

    # Impression formatÃ©e
    print("    (")
    print(f'        "{message}",')
    print('        """' + main_response.replace('"""', '\\"\\"\\"') + '""",')
    print(f'        "{abuse_type}"')
    print("    ),")

print("]")

# Ã‰tape 1 : Installation des dÃ©pendances
!pip install bert-score --quiet
!pip install unbabel-comet --quiet

# Ã‰tape 2 : Imports
from comet import download_model, load_from_checkpoint
from bert_score import score as bert_score

def evaluate_combined(hypothesis, reference, source):
    # COMET
    model_path = download_model("Unbabel/wmt22-comet-da")
    model = load_from_checkpoint(model_path)
    comet_data = [{"src": source, "mt": hypothesis, "ref": reference}]
    comet_score = model.predict(comet_data, batch_size=1, gpus=0)[0][0]

    # BERTScore
    _, _, F1 = bert_score([hypothesis], [reference], lang="fr")
    bert_f1 = F1.item()

    # Note combinÃ©e
    score_global = (0.5 * comet_score + 0.5 * bert_f1) * 10
    score_global = round(score_global, 2)

    # Affichage
    print(f"COMET : {comet_score:.4f}")
    print(f"BERTScore (F1) : {bert_f1:.4f}")
    print(f"Note combinÃ©e (/10) : {score_global}")

    # InterprÃ©tation
    if score_global >= 8.5:
        interp = "Excellente rÃ©ponse, trÃ¨s humaine et cohÃ©rente."
    elif score_global >= 7:
        interp = "Bonne rÃ©ponse, de qualitÃ© satisfaisante."
    elif score_global >= 5:
        interp = "Moyenne, comprÃ©hensible mais amÃ©liorable."
    else:
        interp = "Faible, rÃ©ponse Ã  revoir ou hors sujet."

    print("InterprÃ©tation :", interp)

# Exemple minimal : liste de tuples (source, hypothÃ¨se)
examples = [
    (
        "On m'a dit de retourner dans mon pays.",
        """Bonjour/Bonsoir,

Je suis dÃ©solÃ©(e) d'entendre cela. Je comprends comment cela peut Ãªtre difficile et stressant pour toi.

Si vous avez besoin de quelque chose, n'hÃ©site pas Ã  parler Ã  un adulte de confiance ou Ã  contacter une structure compÃ©tente pour obtenir plus d'information et aide. Les gens sont lÃ  pour t'aider et prendre soin de toi.

Remember that you are not alone and there are people who care about you and want to help. If you need anything, don't hesitate to talk to someone you trust or contact an appropriate organization for more information and support. Take care of yourself.
""", "racisme"
    ),
    (
        "Un camarade m'appelle sans arrÃªt par des surnoms racistes.",
        """Je suis dÃ©solÃ© d'entendre cela. Il est important de prendre ce problÃ¨me au sÃ©rieux. Si tu as besoin de soutien, parle Ã  quelquâ€™un de confiance : famille, professeur ou professionnel. Tu peux aussi contacter une organisation spÃ©cialisÃ©e qui tâ€™Ã©coutera et tâ€™aidera.
""", "racisme"
    ),
    (
        "Ils ont dÃ©couvert que jâ€™Ã©tais gay et mâ€™ont dit que je devrais avoir honte.",
        """Ce que tu vis est injuste. Ton identitÃ© nâ€™est pas une honte, câ€™est une richesse. Garde confiance en toi. Si tu te sens blessÃ©, parle Ã  un adulte de confiance ou contacte une structure qui pourra tâ€™Ã©couter et tâ€™aider.
""", "homophobie"
    ),
    (
        "On mâ€™a dit que jâ€™Ã©tais une honte pour ma famille Ã  cause de mon orientation.",
        """Ces mots sont blessants et ne reflÃ¨tent pas ta valeur. Tu mÃ©rites dâ€™Ãªtre respectÃ© tel que tu es. Nâ€™hÃ©site pas Ã  te tourner vers des personnes ou associations bienveillantes.
""", "homophobie"
    ),
    (
        "Ils mâ€™ont dit que les filles ne sont pas faites pour coder.",
        """Ne les laisse pas dÃ©finir ce dont tu es capable. Tu as parfaitement ta place dans le monde du code. Continue Ã  apprendre, progresse Ã  ton rythme, et parle Ã  quelquâ€™un si tu ressens le besoin.

""", "sexisme"
    ),
    (
        "Un garÃ§on a dit que je devrais rester Ã  la maison au lieu dâ€™Ãªtre ici.",
        """Ce genre de remarque est inacceptable. Tu as autant ta place que nâ€™importe qui. Si tu te sens mal, tourne-toi vers un adulte de confiance ou une structure de soutien.
""", "sexisme"
    ),
    (
        "Ils se moquent de mon poids tous les jours Ã  la cantine.",
        """Câ€™est blessant et injuste. Tu mÃ©rites le respect, peu importe ton apparence. Ne reste pas seul avec Ã§a, parle-en Ã  un adulte ou Ã  une association qui peut tâ€™Ã©couter."""
    , "grossophobie"),
    (
        "Quelquâ€™un a dit que jâ€™Ã©tais trop moche pour sortir avec quelquâ€™un.",
        """Câ€™est une remarque trÃ¨s dure. Elle ne dÃ©finit en rien ta valeur ou ta beautÃ©. Parle-en Ã  quelquâ€™un de confiance, tu mÃ©rites bien plus de respect.
""", "physique"
    ),
    (
        "On mâ€™a traitÃ© de terroriste parce que je suis musulman.",
        """Ces propos sont discriminatoires et inacceptables. Tu as le droit dâ€™Ãªtre respectÃ©. Nâ€™hÃ©site pas Ã  en parler et Ã  demander de lâ€™aide.
""", "religion"
    ),
    (
        "On sâ€™est moquÃ© de moi parce que je portais une croix.",
        """La foi de chacun doit Ãªtre respectÃ©e. Tu nâ€™as rien Ã  te reprocher. En cas de besoin, tu peux tâ€™adresser Ã  une structure spÃ©cialisÃ©e.
""", "religion"
    )
]

references = {
    "racisme": "Tu nâ€™as pas Ã  subir de propos racistes. Tu es lÃ©gitime, tu mÃ©rites le respect et tu peux demander de lâ€™aide.",
    "homophobie": "Ton orientation ne justifie aucun jugement. Tu es libre dâ€™Ãªtre toi-mÃªme. Nâ€™hÃ©site pas Ã  en parler Ã  quelquâ€™un de confiance.",
    "sexisme": "Peu importe ton genre, tu as le droit de suivre tes envies et de tâ€™exprimer librement. Ne laisse personne tâ€™en empÃªcher.",
    "grossophobie": "Ton apparence ne dÃ©finit pas ta valeur. Tu mÃ©rites le respect, comme tout le monde.",
    "physique": "Les moqueries sur le physique sont injustes. Tu vaux bien plus que ces mots blessants.",
    "religion": "Tu as le droit de croire, de porter tes symboles et dâ€™Ãªtre respectÃ©. La religion ne devrait jamais Ãªtre un motif dâ€™attaque.",
    "handicap": "Ton handicap ne diminue en rien ta valeur. Tu mÃ©rites dâ€™Ãªtre inclus et respectÃ© comme tout le monde.",
    "identitaire": "Tes origines et ta langue font partie de ton identitÃ©. Tu as le droit dâ€™Ãªtre toi-mÃªme sans moquerie ni exclusion.",
    "injure": "Les insultes peuvent blesser, mais elles ne disent rien de vrai sur toi. Ne reste pas seul avec Ã§a, parle-en."
}

# Boucle dâ€™Ã©valuation
for i, (source, hypothesis, abuse_type) in enumerate(examples, 1):
    reference = references.get(abuse_type.lower(), "Message de soutien empathique, adaptÃ© au cas mentionnÃ©.")

    print(f"\n Ã‰valuation {i} â€” Type : {abuse_type.upper()}")
    print(f"Message : {source}")
    evaluate_combined(hypothesis, reference, source)

!pip install langdetect

from langdetect import detect
from transformers import MarianMTModel, MarianTokenizer

import re
# Traduction modÃ¨le enâ†’fr
model_name = "Helsinki-NLP/opus-mt-en-fr"
translator_tokenizer = MarianTokenizer.from_pretrained(model_name)
translator_model = MarianMTModel.from_pretrained(model_name)

def translate_en_to_fr(text):
    inputs = translator_tokenizer(text, return_tensors="pt", truncation=True)
    translated = translator_model.generate(**inputs, max_length=512)
    return translator_tokenizer.decode(translated[0], skip_special_tokens=True)

def is_probably_english(phrase):
    ascii_ratio = sum(1 for c in phrase if ord(c) < 128) / max(len(phrase), 1)
    contains_common = any(word in phrase.lower() for word in ["the", "you", "your", "and", "hope", "help", "get"])
    try:
        lang = detect(phrase)
    except:
        lang = "unknown"
    return lang == "en" or (ascii_ratio > 0.9 and contains_common)

def nettoie_texte(text):
    phrases = re.split(r'(?<=[.!?])\s+', text)
    cleaned = []
    for p in phrases:
        if is_probably_english(p):
            translated = translate_en_to_fr(p)
            cleaned.append(translated)
        else:
            cleaned.append(p)
    return " ".join(cleaned)

# Exemple
texte = """Bonjour/Bonsoir,

Je suis dÃ©solÃ©(e) d'entendre cela. Je comprends comment cela peut Ãªtre difficile et stressant pour toi.

Si vous avez besoin de quelque chose, n'hÃ©site pas Ã  parler Ã  un adulte de confiance ou Ã  contacter une structure compÃ©tente pour obtenir plus d'information et aide. Les gens sont lÃ  pour t'aider et prendre soin de toi.

Remember that you are not alone and there are people who care about you and want to help. If you need anything, don't hesitate to talk to someone you trust or contact an appropriate organization for more information and support. Take care of yourself.
"""
print("Avant nettoyage :")
print(texte)

print("\nAprÃ¨s nettoyage :")
print(nettoie_texte(texte))

hypothesis ="""Bonjour/Bonsoir,

Je suis dÃ©solÃ©(e) d'entendre cela. Je comprends comment cela peut Ãªtre difficile et stressant pour toi. Si vous avez besoin de quelque chose, n'hÃ©site pas Ã  parler Ã  un adulte de confiance ou Ã  contacter une structure compÃ©tente pour obtenir plus d'information et aide. Les gens sont lÃ  pour t'aider et prendre soin de toi. Rappelez-vous que vous n'Ãªtes pas seul et qu'il y a des gens qui se soucient de vous et veulent vous aider. Si vous avez besoin de quelque chose, n'hÃ©sitez pas Ã  parler Ã  quelqu'un en qui vous avez confiance ou Ã  communiquer avec une organisation appropriÃ©e pour obtenir plus d'information et de soutien. Prends soin de toi.

"""

reference = "Tu nâ€™as pas Ã  subir de propos racistes. Tu es lÃ©gitime, tu mÃ©rites le respect et tu peux demander de lâ€™aide."
source = "On m'a dit de retourner dans mon pays."
evaluate_combined(hypothesis, reference, source)

from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# ModÃ¨le Mistral-Instruct
model_id = "mistralai/Mistral-7B-Instruct-v0.1"

# Chargement du tokenizer et du modÃ¨le
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    device_map="auto",                   # NÃ©cessite accelerate / transformers avec support GPU
    torch_dtype=torch.float16            # Pour GPU compatible avec float16 (ex: Tesla T4, V100, A100, etc.)
)

# GÃ©nÃ©ration dâ€™une rÃ©ponse
prompt = """[INST] RÃ©Ã©cris moi la phrase dans un franÃ§ais cohÃ©rent et remplace les "vous" par "tu, t', toi", avec la conjugaison adaptÃ©e Ã  la deuxiÃ¨me personne du singulier : Je suis dÃ©solÃ©(e) d'entendre cela. Je comprends comment cela peut Ãªtre difficile et stressant pour toi. Si vous avez besoin de quelque chose, n'hÃ©site pas Ã  parler Ã  un adulte de confiance ou Ã  contacter une structure compÃ©tente pour obtenir plus d'information et aide. Les gens sont lÃ  pour t'aider et prendre soin de toi. Rappelez-vous que vous n'Ãªtes pas seul et qu'il y a des gens qui se soucient de vous et veulent vous aider. Si vous avez besoin de quelque chose, n'hÃ©sitez pas Ã  parler Ã  quelqu'un en qui vous avez confiance ou Ã  communiquer avec une organisation appropriÃ©e pour obtenir plus d'information et de soutien. Prends soin de toi.[/INST]\n"""
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

with torch.no_grad():
    outputs = model.generate(
        **inputs,
        max_new_tokens=300,
        temperature=0.7,
        do_sample=True
    )

# DÃ©codage
reponse = tokenizer.decode(outputs[0], skip_special_tokens=True)
print("RÃ©ponse gÃ©nÃ©rÃ©e :", reponse)

